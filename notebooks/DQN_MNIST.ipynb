{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Networks: MNIST\n",
    "\n",
    "## Getting Started:\n",
    "\n",
    "For this notebook, we'll be following along with the PyTorch tutorial created by sentdex: https://pythonprogramming.net/data-deep-learning-neural-network-pytorch/\n",
    "\n",
    "`torch`: Tensor library similar to NumPy\\\n",
    "`torchvision`: Package from PyTorch with computer vision related datasets, model architectures, and image transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Preparing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`datasets.MNIST`: Dataset of handwritten numbers. 60,000 samples in the training set, 10,000 samples in the test set.\\\n",
    "`transforms.Compose`: Method that composes multiple transforms together.\\\n",
    "`transforms.ToTensor`: Method that converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%d:\\school\\programming\\dl_try\\dl_venv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trainset` - variable to load data into of size 10\\\n",
    "`torch.utils.data.DataLoader` - Dataset and sampler. Provides an interable over the dataset.\n",
    "\n",
    "`train` - Dataset to iterate over.\n",
    "`batch_size` - How many samples per batch to load.\\\n",
    "`shuffle` (Boolean) - Randomly shuffle input data to eliminate patterns in original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([8, 9, 7, 7, 6, 8, 2, 5, 6, 9])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x` (variable) - Features, or **input data**, that we want to predict. Here, it is a tensor of tensors.\\\n",
    "`y` (variable) - Labels, or classification **outputs**, that the neural network is assigning to the input data, `x`.\n",
    "\n",
    "Sees `x`, calls it `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image is 28x28, but data is a 1x28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling/Normalizing, Flattening, and some Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling/Normalization:** Typically, our data will not all be the same or correct sizes. We want all input data to be in the range of 0 to 1, inclusive, so we have to **scale** the values of each pixel in our data to be in this range.\n",
    "\n",
    "`data.view(len,height)` is used to reshape our data. Plotting our data as a 1x28x28 will throw an error, so we use `.view(28,28)` to reshape our data as a 28x28 and `plt.imshow()` to visualize our 28x28 image.\n",
    "\n",
    "**Flatten:** We also have to feed our neural network the data in the form of a vector, so we have to flatten our data from a 1x28x28 into a (1D) vector. We can also do this with `data.view(1,784)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data values of the fourth row of the image are: {tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "print(\"Data values of the fourth row of the image are:\",\\\n",
    "      {data[0][0][0][4]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the values equal 0 for the pixels that are not part of the number, and they are equal to a value in the range of (0,1] when the pixel is part of the number. Because these pixel values are in the range of [0,1], rather than typical RGB values (3-tuple/triple of values [0,255]), we know that our data is already scaled!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Balance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balancing:** We should make sure that our dataset includes an equal amount of each class. With 60,000 samples and 10 different classes (0-9), we would want 6,000 samples of each number.\\\n",
    "*Otherwise, our classifier would learn that it could be correct a majority of the time by choosing the class with the highest number of samples.*\n",
    "\n",
    "To figure out how balanced our data is, we can iterate over our dataset and count how many samples of each class we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.871666666666666%\n",
      "1: 11.236666666666666%\n",
      "2: 9.93%\n",
      "3: 10.218333333333334%\n",
      "4: 9.736666666666666%\n",
      "5: 9.035%\n",
      "6: 9.863333333333333%\n",
      "7: 10.441666666666666%\n",
      "8: 9.751666666666667%\n",
      "9: 9.915000000000001%\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "numbers = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    xs, ys = data\n",
    "    for y in ys:\n",
    "        numbers[int(y)] += 1\n",
    "        tot += 1\n",
    "        \n",
    "print(numbers)\n",
    "\n",
    "for i in numbers:\n",
    "    print(f\"{i}: {numbers[i]/tot*100.0}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's balanced enough because guessing the same number would give us 11% at best and 9% at worst. If the distribution were greater (like a 30% difference), then we'd have trouble training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fc1`: Variable for our first fully connected layer. Input is our vector of feature values, which will be a flattened 28p x 28p tensor, i.e. a vector of 784pixels, and our output can be any value we want, but 64 is nice.\\\n",
    "`fc2`, `fc3` and `fc4` inputs are 64 because the size of the output at the layer before it is 64. The output of `fc4` is 10 because there are 10 classes of numbers that it will output.\n",
    "\n",
    "\n",
    "`nn.Linear`: Fully connected layer. Convolutional layer is `nn.Conv`.\n",
    "\n",
    "`forward()`: is the method where we define how the data flows through the layers we've defined. The first parameter is `self`, or the class that we've instantiated, and the second parameter is `x`, or the input data.\n",
    "\n",
    "`F.relu()`: Rectified Linear activation function. Tells us whether the neuron is activated/firing by the value of its output (the second value).\n",
    "\n",
    "`F.log_softmax(x, dim=1)`: log_softmax is a popular choice to use as the final activation function for a classification network. This normalizes the output `x` into a probability distribution over the output classes `dim=1`. If we used `dim=0`, we'd normalize the data over the batches, rather than the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also implement some logic into the `forward` method to pass the data into the next layer under particular conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, consider a neural network trying to learn an optimal control policy for a diabetic patient. If the patient were an adolescent, the data could pass through one set of activation functions, but if the patient were an adult, the data might pass through another set of activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Neural Network with some Random Data\n",
    "\n",
    "Below, we generate some random input data `x` to simulate a 28x28 pixel image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the data to a (-1, 784), then pass it through the neural network with `net()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2810, -2.2865, -2.4614, -2.3590, -2.4126, -2.2243, -2.2084, -2.2526,\n",
       "         -2.2580, -2.3116]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(x.view(-1,784))\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output of a tensor within a tensor is the neural network's probability distribution of the random input values `x` over the 10 different characters, and the gradient function used to obtain these output values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loss_f`: Variable defining our loss function. This tells us the error between our targeted output and our neural network's guess. The target outputs will determine our loss function.\n",
    "- `nn.one_hot`: A class of loss functions. Makes the neural network's guess a scalar and the rest are 0's. For instance, a one_hot vector for inputting a sample of a \"3\" would read:\\\n",
    "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "- `nn.CrossEntropyLoss()`: Another class of loss functions.\n",
    "\n",
    "`optimizer`: Variable for our neural network's optimizer. Tunes model parameters (like weights) to fit the data.\n",
    "- `optim.Adam()`: Adaptive Momentum optimizer, popular for (???). \n",
    " - `lr()`: The learning rate of our neural network. Determines the magnitude of changes that the optimizer can make at each step, which is proportional to the rate that our model learns. If `lr` too high, it will vary its searches too much and won't improve. If `lr` too low, it might get stuck at a suboptimal solution.\n",
    " - Probably need to use a decaying learning rate. Want to learn quickly, but we still want to improve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An epoch is one cycle through the full dataset. Too few and our neural network won't fully learn; too many and our neural network will overfit to our \"in-sample data\", meaning it will perform well with the data it had sampled from, but it won't perform well with data outside of these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3): #3 passes over data\n",
    "    for data in trainset: # `data` is a batch of data\n",
    "        x, y = data # x is batch of features, y is batch of targets\n",
    "        net.zero_grad() # gradient = 0 before calculating loss\n",
    "        output = net(x.view(-1,784)) # pass flattened batch through network\n",
    "        loss = F.nll_loss(output, y) # calculate loss and record it\n",
    "        loss.backward() # send loss back through network params\n",
    "        optimizer.step() # tune weights to account for the loss/grad\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  97.752 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        x, y = data\n",
    "        output = net(x.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1 #Checking to see if our prediction was correct\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy: \", round(100*correct/total, 3), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This accuracy of >95% is relatively uncommon with real data. Be suspicious if this occurs.\n",
    "\n",
    "To check out how it's reading:\n",
    "- We plot the 0th `x[0]` tensor (image) of `x` as a 28x28p image by reshaping it to that size with `view()`.\n",
    "- We can flatten the image again with `view(-1, 784)` and print the neural network's most confident class prediction using `torch.argmax` on the flattened vector of the 0th `x[0]` tensor (image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x[0].view(28,28))\n",
    "plt.show()\n",
    "print(torch.argmax(net(x[0].view(-1,784))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I did this, the image depicted a 7 and the network classified it as a 7, so I know it's working. If you did this correctly and the neural network gets it wrong, you're pretty unlucky, because we just saw that this neural network was __% accurate from the previous text. Check the other x's, too (x[4], x[10], ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}